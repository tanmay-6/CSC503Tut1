{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b5f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2fc05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "X,Y = make_classification(n_samples=100000, n_classes=2, weights=[0.995,0.005], flip_y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d62b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99500   500]\n",
      "0.005\n",
      "Counter({np.int64(0): 99500, np.int64(1): 500})\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(Y))\n",
    "print(np.mean(Y))\n",
    "print(Counter(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1476e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 20)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8af7289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 20)\n",
      "(20000, 20)\n",
      "(80000,)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f793065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, counts = np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06f534f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minority = 1\n",
    "A = x_train[y_train == 1] #creating minority matrix named A.\n",
    "datapoints_to_add = counts[0]-counts[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe48fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(X):\n",
    "    D = np.zeros((X.shape[0],X.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            D[i,j] = np.sqrt(np.sum((X[i]-X[j])**2))\n",
    "    return D\n",
    "\n",
    "def knn(X, k):\n",
    "    D = euclidean_distance(X)\n",
    "    np.fill_diagonal(D, np.inf)\n",
    "    return np.argpartition(D, kth=k-1, axis=1)[:,:k]\n",
    "\n",
    "def smote(A, n_new, k=5, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    n, d = A.shape\n",
    "    if n<2:\n",
    "        raise ValueError(\"Need at least 2 minority samples for SMOTE\")\n",
    "    if k<1 or k >= n:\n",
    "        raise ValueError(\"k must be in range [1,n-1].\")\n",
    "    \n",
    "    nbrs = knn(A, k=k)\n",
    "    base_index = rng.integers(low=0, high=n, size=n_new)\n",
    "    ngbr_choice = rng.integers(low=0, high=k, size=n_new)\n",
    "    ngbr_index = nbrs[base_index, ngbr_choice]\n",
    "    u = rng.random(n_new).astype(A.dtype)\n",
    "\n",
    "    P = A[base_index]\n",
    "    Q = A[ngbr_index]\n",
    "    Z = P + (u[:,None] * (Q-P))\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6462064",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_syn = smote(A, datapoints_to_add)\n",
    "y_syn = np.full(shape=(A_syn.shape[0],), fill_value=1, dtype=y_train.dtype)\n",
    "\n",
    "xp_train = np.vstack([x_train, A_syn])\n",
    "yp_train = np.concatenate([y_train, y_syn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c6ebedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b62adcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19892\n",
      "           1       0.87      0.25      0.39       108\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.93      0.62      0.69     20000\n",
      "weighted avg       1.00      1.00      0.99     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imbmodel = LogisticRegression()\n",
    "imbmodel.fit(x_train, y_train)\n",
    "y_pred_imb = imbmodel.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_imb)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred_imb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caacb587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     19892\n",
      "           1       0.05      0.92      0.09       108\n",
      "\n",
      "    accuracy                           0.90     20000\n",
      "   macro avg       0.52      0.91      0.52     20000\n",
      "weighted avg       0.99      0.90      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bmodel = LogisticRegression()\n",
    "bmodel.fit(xp_train, yp_train)\n",
    "y_pred_bal = bmodel.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_bal)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "619c5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04872047244094488 0.9166666666666666 0.09252336448598131 108\n",
      "0.8709677419354839 0.25 0.38848920863309355 108\n",
      "\n",
      "Recall for minority class in balancned set 0.9166666666666666\n",
      "Recall for minority class in imbalancned set 0.25\n"
     ]
    }
   ],
   "source": [
    "#analysis\n",
    "#minority class = 1\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_test, y_pred_bal)\n",
    "pp,rp,fp,sp = precision_recall_fscore_support(y_test, y_pred_imb)\n",
    "\n",
    "print(p[1], r[1], f[1], s[1])\n",
    "print(pp[1], rp[1], fp[1], sp[1])\n",
    "\n",
    "print()\n",
    "print(\"Recall for minority class in balancned set\", r[1])\n",
    "print(\"Recall for minority class in imbalancned set\", rp[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44e0f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fraud detection system, we cannot ignore actual positive that is predicted negative, therefore False Negatives should be consider in the matrix, which means RECALL is important metric for same.\n",
      "Smote typically improves recall by exposing the model to more minority examples which are synthetically created\n",
      "Therefore, the SMOTE-balanced model is generally preferable when recall is the priority.\n"
     ]
    }
   ],
   "source": [
    "print(\"For fraud detection system, we cannot ignore actual positive that is predicted negative, therefore False Negatives should be consider in the matrix, which means RECALL is important metric for same.\")\n",
    "print(\"Smote typically improves recall by exposing the model to more minority examples which are synthetically created\")\n",
    "print(\"Therefore, the SMOTE-balanced model is generally preferable when recall is the priority.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
